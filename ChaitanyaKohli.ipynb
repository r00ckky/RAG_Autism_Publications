{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkDKimmhwmBz",
        "outputId": "ce37a387-4189-423b-8c78-04f9e8621137"
      },
      "outputs": [],
      "source": [
        "import PyPDF2\n",
        "from PyPDF2 import PdfReader\n",
        "import os\n",
        "from glob import glob\n",
        "import random as rand\n",
        "import langdetect\n",
        "import openai\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "openai.api_key=os.environ.get('OPENAI_API_KEY')\n",
        "from tenacity import (\n",
        "    retry,\n",
        "    stop_after_attempt,\n",
        "    wait_random_exponential,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZh3Yklq5tSE"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ddiHCJzV1GgU"
      },
      "outputs": [],
      "source": [
        "pdfs = glob('Publications/*.pdf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttkd7qWl4FpR"
      },
      "source": [
        "### Checking wether the PDF is readable or not"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S73ZBWAZ1a28",
        "outputId": "dcf5bd0a-ac95-48e3-dd82-0b0d553bbcc6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Multiple definitions in dictionary at byte 0x1cc6b for key /MediaBox\n",
            "Multiple definitions in dictionary at byte 0x1ce61 for key /MediaBox\n",
            "Multiple definitions in dictionary at byte 0x1d014 for key /MediaBox\n",
            "Multiple definitions in dictionary at byte 0x1d1ae for key /MediaBox\n",
            "Multiple definitions in dictionary at byte 0x1d33d for key /MediaBox\n",
            "Multiple definitions in dictionary at byte 0x1d4af for key /MediaBox\n",
            "Multiple definitions in dictionary at byte 0x1d699 for key /MediaBox\n",
            "Multiple definitions in dictionary at byte 0x1d85b for key /MediaBox\n",
            "Multiple definitions in dictionary at byte 0x1db05 for key /MediaBox\n",
            "Multiple definitions in dictionary at byte 0x1cc6b for key /MediaBox\n",
            "Multiple definitions in dictionary at byte 0x1ce61 for key /MediaBox\n",
            "Multiple definitions in dictionary at byte 0x1d014 for key /MediaBox\n",
            "Multiple definitions in dictionary at byte 0x1d1ae for key /MediaBox\n",
            "Multiple definitions in dictionary at byte 0x1d33d for key /MediaBox\n",
            "Multiple definitions in dictionary at byte 0x1d4af for key /MediaBox\n",
            "Multiple definitions in dictionary at byte 0x1d699 for key /MediaBox\n",
            "Multiple definitions in dictionary at byte 0x1d85b for key /MediaBox\n",
            "Multiple definitions in dictionary at byte 0x1db05 for key /MediaBox\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Publications/15_Nazneen.pdf', 'Publications/Tariq_2019.pdf', 'Publications/Asd_Cry_patterns.pdf', 'Publications/Tariq2018.pdf']\n",
            "['Publications/Young_Behavior.pdf', 'Publications/1_Ramırez-Duque_.pdf', 'Publications/Patten_Audio.pdf', 'Publications/zhao2020.pdf', 'Publications/carpenter2020 (1).pdf', 'Publications/LEE.pdf', 'Publications/Abbas_2020.pdf', 'Publications/Dawson.pdf', 'Publications/Qiu.pdf', 'Publications/22_Ouss_ASD.pdf', 'Publications/Abbas_2018.pdf']\n"
          ]
        }
      ],
      "source": [
        "unreadable_pdfs = []\n",
        "readable_pdfs = []\n",
        "for pdf in pdfs:\n",
        "  reader = PdfReader(pdf)\n",
        "  page = reader.pages[0]\n",
        "  text = page.extract_text()\n",
        "  if text == '':\n",
        "    unreadable_pdfs.append(pdf)\n",
        "  else:\n",
        "    readable_pdfs.append(pdf)\n",
        "    \n",
        "for pdf in readable_pdfs:\n",
        "  _pdf = PdfReader(pdf)\n",
        "  page = _pdf.pages[0]\n",
        "  text = page.extract_text()\n",
        "  if langdetect.detect(text)!='en':\n",
        "    unreadable_pdfs.append(pdf)\n",
        "    readable_pdfs.remove(pdf)\n",
        "\n",
        "print(unreadable_pdfs)\n",
        "print(readable_pdfs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "eTsuzVJ4L0zC",
        "outputId": "2c72ad23-99d0-4d40-bbee-45fbcf55d1cf"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import easyocr\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "# import fitz\n",
        "\n",
        "# class OCR:\n",
        "#     def __init__(self, lang:str, gpu:bool=True):\n",
        "#         super().__init__()\n",
        "#         self.device = 'cpu' if not gpu else torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#         if self.device == 'cpu' and gpu:\n",
        "#             print(\"GPU not available, using CPU instead\")\n",
        "#         self.lang = lang\n",
        "#         self.reader = easyocr.Reader([lang], gpu=True if self.device=='cuda' else False)\n",
        "\n",
        "#     def get_bbox(self, img)->np.array:\n",
        "#         \"\"\"Get bounding box of text in image format (x_min, x_max, y_min, y_max)\"\"\"\n",
        "#         bbox = np.array(self.reader.detect(img)[0][0])\n",
        "#         return bbox\n",
        "\n",
        "#     def read_img(self, img_path)->np.array:\n",
        "#         \"\"\"Read image and return image\"\"\"\n",
        "#         img = cv2.imread(img_path)\n",
        "#         img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "#         return img\n",
        "\n",
        "#     def get_text(self, img, detail=0)->str:\n",
        "#         \"\"\"return text from image\"\"\"\n",
        "#         text = self.reader.readtext(img, detail=detail)\n",
        "#         return text\n",
        "\n",
        "# class pdf2images:\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "\n",
        "#     def get_images_from_pdf(self, idx, pdf_path, output_folder:str=None, save_images_locally:bool=False):\n",
        "#         if save_images_locally:\n",
        "#             if output_folder is None:\n",
        "#                 raise ValueError(\"output_folder must be specified if save_images_locally is True\")\n",
        "#             if not os.path.exists(output_folder):\n",
        "#                 os.makedirs(output_folder)\n",
        "#         doc = fitz.open(pdf_path)\n",
        "#         count = idx\n",
        "#         j = 0\n",
        "#         for i in doc:\n",
        "#             images = i.get_pixmap()\n",
        "#             images.save(str(count)+'_'+str(j)+\".png\")\n",
        "#             j+=1\n",
        "#             count+=1\n",
        "#         return count\n",
        "\n",
        "#     def pdfs_to_images(self, pdf_paths, output_folder, save_images_locally:bool=False):\n",
        "#         idx=0\n",
        "#         for pdf_path in pdf_paths:\n",
        "#             idx = self.get_images_from_pdf(idx = idx, pdf_path = pdf_path, output_folder = output_folder, save_images_locally = save_images_locally)\n",
        "# pdf_image_gen = pdf2images()\n",
        "# ocr = OCR('en')\n",
        "# OUTPUT_PATH = '/content/drive/MyDrive/Publications_images'\n",
        "# pdf_image_gen.pdfs_to_images(unreadable_pdfs, OUTPUT_PATH, save_images_locally=True)\n",
        "# images_path = glob('/content/drive/MyDrive/Publications_images/*.png')\n",
        "# for image in images_path:\n",
        "#   img = ocr.read_img(image)\n",
        "#   text = ocr.get_text(img)\n",
        "#   print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "uVDR84iPbphq"
      },
      "outputs": [],
      "source": [
        "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
        "def generate_text(prompt:str, sys_prompt:str, temperature:float=0.01):\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": sys_prompt\n",
        "        },\n",
        "        {\n",
        "            'role':'user',\n",
        "            'content':prompt\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo-1106\",\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "        max_tokens=1000,\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message['content']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The input is New Text from research paper, and the Previous Text has been cleaned already. From the New Text remove the table data, the refrences, and the figure, while keeping the core of the text same. If possible summarise the table data, and what the figure was for.\n"
          ]
        }
      ],
      "source": [
        "system_prompt = \"\"\"The input is New Text from research paper, and the Previous Text has been cleaned already. From the New Text remove the table data, the refrences, and the figure, while keeping the core of the text same. If possible summarise the table data, and what the figure was for.\"\"\"\n",
        "print(system_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Multiple definitions in dictionary at byte 0x1cc6b for key /MediaBox\n",
            "Multiple definitions in dictionary at byte 0x1ce61 for key /MediaBox\n",
            "Multiple definitions in dictionary at byte 0x1d014 for key /MediaBox\n",
            "Multiple definitions in dictionary at byte 0x1d1ae for key /MediaBox\n",
            "Multiple definitions in dictionary at byte 0x1d33d for key /MediaBox\n",
            "Multiple definitions in dictionary at byte 0x1d4af for key /MediaBox\n",
            "Multiple definitions in dictionary at byte 0x1d699 for key /MediaBox\n",
            "Multiple definitions in dictionary at byte 0x1d85b for key /MediaBox\n",
            "Multiple definitions in dictionary at byte 0x1db05 for key /MediaBox\n"
          ]
        }
      ],
      "source": [
        "for pdf_path in readable_pdfs:\n",
        "  pdf = PdfReader(pdf_path)\n",
        "  cleaned_text = ''\n",
        "  for page in pdf.pages:\n",
        "    text = page.extract_text()\n",
        "    text = text.lower()\n",
        "    prompt = f\"\"\"Previous Text: {cleaned_text}\n",
        "    New Text{text}\"\"\"\n",
        "    cleaned_text = cleaned_text+generate_text(prompt, system_prompt, temperature=0.2)\n",
        "      \n",
        "  with open(os.path.join('Texts' ,f\"f{pdf_path.split('/')[-1].split('.')[0]}.txt\"), 'w') as f:\n",
        "    f.write(cleaned_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pymongo\n",
        "import openai\n",
        "import langchain\n",
        "import langchain_openai\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from pymongo import MongoClient\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "import pandas as pd\n",
        "from langchain.chains import question_answering\n",
        "from langchain.docstore.document import Document\n",
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_core.prompt_values import PromptValue\n",
        "import numpy as np\n",
        "MONGO_CONNECTION_STRING = os.environ.get('MONGODB_ATLAS_CONNECTION_STRING')\n",
        "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "client = MongoClient(MONGO_CONNECTION_STRING)\n",
        "dbName = 'Publications'\n",
        "collectionName = 'Embedding_of_publications'\n",
        "collection = client[dbName][collectionName]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "loader = DirectoryLoader('./Texts', glob='./*.txt')\n",
        "data = loader.load()\n",
        "content = {}\n",
        "for doc in data:\n",
        "    content.update({doc.metadata['source'].split('/')[-1].split('.')[0] : doc.page_content.split('.\\n\\n')})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1_Ramırez-Duque_ Done\n",
            "fYoung_Behavior Done\n",
            "fPatten_Audio Done\n",
            "fAbbas_2018 Done\n",
            "fQiu Done\n",
            "fzhao2020 Done\n",
            "fcarpenter2020 (1) Done\n",
            "fDawson Done\n",
            "f22_Ouss_ASD Done\n",
            "fLEE Done\n",
            "fAbbas_2020 Done\n"
          ]
        }
      ],
      "source": [
        "for file in content.keys():\n",
        "    print(file, end=' ')\n",
        "    data = []\n",
        "    for text in content[file]:\n",
        "        embed = embeddings.embed_documents([text])\n",
        "        data.append({\"embeddings\":embed, \"text\":text})\n",
        "    collection.insert_many(data)\n",
        "    print('Done')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "for doc in collection.find():\n",
        "    arr = doc['embeddings']\n",
        "    flat_arr = np.array(arr).flatten()\n",
        "    query = {'_id':doc['_id']}\n",
        "    update = {\"$set\":{'embeddings':flat_arr.tolist()}}\n",
        "    collection.update_one(query, update)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import pymongo\n",
        "# import datetime\n",
        "\n",
        "# # connect to your Atlas cluster\n",
        "# client = pymongo.MongoClient(\"<connection-string>\")\n",
        "\n",
        "# # define pipeline\n",
        "# pipeline = [\n",
        "#   {\n",
        "#     '$vectorSearch': {\n",
        "#       'index': 'vector-search-tutorial', \n",
        "#       'path': 'plot_embedding', \n",
        "#       'filter': {\n",
        "#         '$or': [\n",
        "#           {\n",
        "#             'genres': {\n",
        "#               '$ne': 'Crime'\n",
        "#             }\n",
        "#           }, {\n",
        "#             '$and': [\n",
        "#               {\n",
        "#                 'year': {\n",
        "#                   '$lte': 2015\n",
        "#                 }\n",
        "#               }, {\n",
        "#                 'genres': {\n",
        "#                   '$eq': 'Action'\n",
        "#                 }\n",
        "#               }\n",
        "#             ]\n",
        "#           }\n",
        "#         ]\n",
        "#       }, \n",
        "#       'queryVector': [],\n",
        "#       'numCandidates': 200, \n",
        "#       'limit': 10\n",
        "#     }\n",
        "#   }, {\n",
        "#     '$project': {\n",
        "#       '_id': 0, \n",
        "#       'title': 1, \n",
        "#       'genres': 1, \n",
        "#       'plot': 1, \n",
        "#       'year': 1, \n",
        "#       'score': {\n",
        "#         '$meta': 'vectorSearchScore'\n",
        "#       }\n",
        "#     }\n",
        "#   }\n",
        "# ]\n",
        "\n",
        "# # run pipeline\n",
        "# result = client[\"sample_mflix\"][\"embedded_movies\"].aggregate(pipeline)\n",
        "\n",
        "# # print results\n",
        "# for i in result:\n",
        "#     print(i)\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "queries = pd.read_csv('Query.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_pipline(query):\n",
        "    queryVector = embeddings.embed_documents([query])\n",
        "    queryVector = np.array(queryVector).flatten()\n",
        "    pipeline = [{\n",
        "        \"$vectorSearch\": {\n",
        "            \"index\": \"vector_index\",\n",
        "            \"path\": \"embeddings\",\n",
        "            \"queryVector\": queryVector.tolist(),\n",
        "            \"numCandidates\": 200,\n",
        "            \"limit\": 10\n",
        "        }\n",
        "    }]\n",
        "    return pipeline\n",
        "\n",
        "def similarity_search(query):\n",
        "    pipeline = make_pipline(query)\n",
        "    result = collection.aggregate(pipeline)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "def document_retrival(query):\n",
        "    sample_query = queries.sample(n=1)['Questions '].to_list()[0]\n",
        "    retrived_vectors = similarity_search(sample_query)\n",
        "    list_vectors = [Document(i['text']) for i in retrived_vectors]\n",
        "    return list_vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In conclusion, the study contributes to the understanding of early screening methods for high-risk ASD and provides insights into the social behaviors and developmental differences between high-risk ASD and typical development groups in early childhood.The new text discusses the social communication impairments and stereotyped behaviors in infants and toddlers with high-risk autism spectrum disorder (ASD). It highlights the differences in social behaviors between high-risk and typical development groups during the still-face paradigm (SFP) episode. The study also employs machine learning methods, including support vector machine (SVM), naïve Bayes, and random forest, to construct models for early ASD screening. The SVM model is found to have the best performance, especially for the still-face episode. However, there are challenges in differentiating non-ASD from ASD groups, and the classification accuracy does not show regularity with month age. The study acknowledges limitations in sample size and age matching between the high-risk and typical development groups and emphasizes the need for further research with expanded sample sizes and controlled physiological and psychological ages'"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "document_retrival(queries.sample(n=1)['Questions '].to_list()[0])[0].page_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PublicationsRAG:\n",
        "    def __init__(self, model:str, api_key:str) -> None:\n",
        "        self.llm = ChatOpenAI(api_key=api_key, model= model)\n",
        "        self.chain = question_answering.load_qa_chain(llm = self.llm, chain_type=\"map_reduce\")\n",
        "        self.document_summary_llm = ChatOpenAI(api_key=api_key, model=model)\n",
        "        self.document_summary_llm.invoke([\n",
        "            SystemMessage(\n",
        "                content=\"Summarise the documents according to the question\"\n",
        "            )\n",
        "        ])\n",
        "        \n",
        "    def __make_pipline(self, query)->list[dict]:\n",
        "        queryVector = embeddings.embed_documents([query])\n",
        "        queryVector = np.array(queryVector).flatten()\n",
        "        pipeline = [{\n",
        "            \"$vectorSearch\": {\n",
        "                \"index\": \"vector_index\",\n",
        "                \"path\": \"embeddings\",\n",
        "                \"queryVector\": queryVector.tolist(),\n",
        "                \"numCandidates\": 200,\n",
        "                \"limit\": 10\n",
        "            }\n",
        "        }]\n",
        "        return pipeline\n",
        "    \n",
        "    def __similarity_search(self, query)->list[Document]:\n",
        "        pipeline = self.__make_pipline(query)\n",
        "        result = collection.aggregate(pipeline)\n",
        "        list_documents = [Document(i['text']) for i in result]\n",
        "        return list_documents\n",
        "    \n",
        "    def __document_summary(self, documents, query):\n",
        "        documents = [i.page_content for i in documents]\n",
        "        uni_document = '\\n\\n'.join(set(documents))\n",
        "        summary = self.document_summary_llm.invoke([\n",
        "            HumanMessage(\n",
        "                content=f\"Query:{query}\\nDocument:{documents}\"\n",
        "            )\n",
        "        ])\n",
        "        summary = [Document(i) for i in summary.content.split('\\n\\n')]\n",
        "        return summary, uni_document\n",
        "        \n",
        "    def query_run(self, query):\n",
        "        documents = self.__similarity_search(query)\n",
        "        summary_document, documents = self.__document_summary(documents, query)\n",
        "        return self.chain.run(input_documents = summary_document, question=query), documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "rag = PublicationsRAG('gpt-3.5-turbo', OPENAI_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_queries = queries['Questions '].to_list()\n",
        "answer = []\n",
        "documents = []\n",
        "for query in sample_queries:\n",
        "    ans, doc = rag.query_run(query)\n",
        "    answer.append(ans)\n",
        "    documents.append(doc)\n",
        "\n",
        "queries['answer'] = answer\n",
        "queries['documents'] = documents\n",
        "queries.to_csv('Answers.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
