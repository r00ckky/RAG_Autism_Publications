The study aimed to assess the utility of a tablet-based behavioral assessment for detecting atypical patterns of facial expression in toddlers with autism spectrum disorder (ASD). The assessment involved toddlers watching brief movies on a tablet while their facial expressions were recorded using the embedded camera. Computer vision analysis (CVA) was used to automatically detect and track facial landmarks, enabling the estimation of head position and facial expressions. The results indicated that the CVA could reliably differentiate between children with and without ASD based on their patterns of facial movement and expressions. Children with ASD more frequently displayed neutral expressions, while those without ASD had more expressions indicative of engagement/interest. The study suggests that computational assessments of facial expressions via a tablet-based assessment may be useful in the early detection of symptoms of autism.

The table data in the original text has been removed, and the figure was not described in the provided text. If you can provide a description of the figure, I can help summarize it. Additionally, the references have been removed from the text.The new text discusses the need for feasible, scalable, and reliable tools to characterize ASD risk behaviors in children. It mentions the use of computer vision analysis (CVA) to develop tools for digitally phenotyping early emerging risk behaviors for ASD. The text also highlights the importance of facial expressions as a potential early risk marker for young children with autism, citing previous research on atypical facial expressions in children with ASD. It discusses the limitations of previous research that relied on hand-coding of facial expressions and the move towards automating the coding of facial expressions using CVA technology.

Additionally, the text describes the development of a portable tablet-based technology that uses the embedded camera and automatic CVA to code ASD risk behaviors in less than 10 minutes across various non-laboratory settings. This technology aims to capture children's attention, elicit emotional responses, and assess their ability to sustain attention and share it with others.

The table data from the original text has been removed, and the figure was not described. If you can provide a description of the figure, I can help summarize it.The new text discusses the development of a tablet-based assessment tool using computer vision analysis (CVA) to detect facial movement and affect in young children, particularly focusing on differentiating children with and without ASD based on facial affect. The goal is to create an objective, efficient, and accessible tool for early detection of ASD risk behaviors. The study involved 104 children aged 16-31 months, including typically developing children, those with non-ASD delays, and those diagnosed with ASD. The participants were recruited from pediatric primary care settings and the community, and screening for ASD was conducted using the digital M-CHAT-R/F and diagnostic testing with ADOS-Toddler. The study aims to combine information across various autism risk features to develop a risk score based on multiple behaviors, enhancing screening for ASD.

The table data in the original text provides sample demographics, including age, sex, ethnicity/race, insurance, and M-CHAT result for typically developing children, those with non-ASD delays, and those diagnosed with ASD. The figure, which is not described, likely represents the facial expressions and movements recorded during the tablet-based assessment using CVA.The new text discusses the use of a tablet-based assessment tool using computer vision analysis (CVA) to detect facial movement and affect in young children, particularly focusing on differentiating children with and without ASD based on facial affect. The study involved 104 children aged 16-31 months, including typically developing children, those with non-ASD delays, and those diagnosed with ASD. The participants were recruited from pediatric primary care settings and the community, and screening for ASD was conducted using the digital M-CHAT-R/F and diagnostic testing with ADOS-Toddler. The study aims to combine information across various autism risk features to develop a risk score based on multiple behaviors, enhancing screening for ASD.

The figure likely represents the facial expressions and movements recorded during the tablet-based assessment using CVA. The stimuli and procedure involved showing developmentally appropriate brief movies designed to elicit affect and engage the child’s attention on a tablet while the child sat on a caregiver’s lap. The tablet was placed on a stand approximately 3 ft away from the child to prevent the child from touching the screen. The movies consisted of cascading bubbles, a mechanical bunny, animal puppets interacting with each other, and a split screen showing a woman singing nursery rhymes on one side and dynamic, noise-making toys on the other side. These movies included stimuli that have been used in previous studies of ASD symptomatology, as well as those developed specifically for the current tablet-based technology to elicit autism symptoms.

The computer vision analysis involved the frontal camera in the tablet recording video throughout the experiment at 1280 × 720 resolution and 30 frames per second. The CVA algorithm automatically detected and tracked 49 facial landmarks on the child’s face and estimated head positions relative to the camera. It assigned a "not visible" tag to frames where the face was not detected or exhibited drastic yaw. For each "visible" frame, the probability of expressing three standard categories of facial expressions (positive, neutral, and negative) was determined.

The table data in the original text provided sample demographics, including age, sex, ethnicity/race, insurance, and M-CHAT result for typically developing children, those with non-ASD delays, and those diagnosed with ASD. The study found that children in the ASD group were, on average, 4 months younger than the comparison group, and there was a higher proportion of males in the ASD group. Additionally, there were no differences in the proportion of racial/ethnic minority children between the two groups, and no difference in the proportion of children on Medicaid in the ASD and the non-ASD group.The new text discusses the development of a tablet-based assessment tool using computer vision analysis (CVA) to detect facial movement and affect in young children, particularly focusing on differentiating children with and without ASD based on facial affect. The study involved 104 children aged 16-31 months, including typically developing children, those with non-ASD delays, and those diagnosed with ASD. The participants were recruited from pediatric primary care settings and the community, and screening for ASD was conducted using the digital M-CHAT-R/F and diagnostic testing with ADOS-Toddler. The study aims to combine information across various autism risk features to develop a risk score based on multiple behaviors, enhancing screening for ASD.

The figure likely represents the odds ratio analysis using the “rhymes and toys” movie as one illustrative example. The figure depicts the variability in the odds ratio estimates, showing that some parts of the movies elicited strongly differential responses in certain patterns of expression, while in other sections, there were not substantial differences between the two groups. Overlaid on the plot are the odds ratios and confidence bands for the interval parameters selected by the expression-specific lasso models. These selected parameters were then used in the movie-level logistic models for which classification metrics were calculated.

The table data in the original text provided sample demographics, including age, sex, ethnicity/race, insurance, and M-CHAT result for typically developing children, those with non-ASD delays, and those diagnosed with ASD. The study found that children in the ASD group were, on average, 4 months younger than the comparison group, and there was a higher proportion of males in the ASD group. Additionally, there were no differences in the proportion of racial/ethnic minority children between the two groups, and no difference in the proportion of children on Medicaid in the ASD and the non-ASD group.

The references and the detailed technical information about the CVA algorithm have been removed from the new text. The figure described in the new text is an illustrative example of the odds ratio analysis using the “rhymes and toys” movie, showing the variability in the odds ratio estimates for different patterns of expression in children with and without ASD.The new text discusses the development of a tablet-based assessment tool using computer vision analysis (CVA) to detect facial movement and affect in young children, particularly focusing on differentiating children with and without ASD based on facial affect. The study involved 104 children aged 16-31 months, including typically developing children, those with non-ASD delays, and those diagnosed with ASD. The participants were recruited from pediatric primary care settings and the community, and screening for ASD was conducted using the digital M-CHAT-R/F and diagnostic testing with ADOS-Toddler. The study aims to combine information across various autism risk features to develop a risk score based on multiple behaviors, enhancing screening for ASD.

The figure likely represents the odds ratio analysis using the “rhymes and toys” movie as one illustrative example. The figure depicts the variability in the odds ratio estimates, showing that some parts of the movies elicited strongly differential responses in certain patterns of expression, while in other sections, there were not substantial differences between the two groups. Overlaid on the plot are the odds ratios and confidence bands for the interval parameters selected by the expression-specific lasso models. These selected parameters were then used in the movie-level logistic models for which classification metrics were calculated.

The table data in the original text provided sample demographics, including age, sex, ethnicity/race, insurance, and M-CHAT result for typically developing children, those with non-ASD delays, and those diagnosed with ASD. The study found that children in the ASD group were, on average, 4 months younger than the comparison group, and there was a higher proportion of males in the ASD group. Additionally, there were no differences in the proportion of racial/ethnic minority children between the two groups, and no difference in the proportion of children on Medicaid in the ASD and the non-ASD group.

The references and the detailed technical information about the CVA algorithm have been removed from the new text. The figure described in the new text is an illustrative example of the odds ratio analysis using the “rhymes and toys” movie, showing the variability in the odds ratio estimates for different patterns of expression in children with and without ASD. The figure compares the roc curves for the final movie-level logistic models after leave-one-out cross-validation. The analysis was performed for each video individually, and the model for the “rhymes” movie yielded the strongest predictive ability, followed by the “puppets” and the “bunny” videos. The two “bubbles” movies were the least predictive. The study also explored specific facial movements driving the category of other expressions and how it differs from the neutral expression category, using the CVA algorithm to align facial landmarks and quantify distances between specific facial features.The new text discusses the development of a tablet-based assessment tool using computer vision analysis (CVA) to detect facial movement and affect in young children, particularly focusing on differentiating children with and without ASD based on facial affect. The study involved 104 children aged 16-31 months, including typically developing children, those with non-ASD delays, and those diagnosed with ASD. The participants were recruited from pediatric primary care settings and the community, and screening for ASD was conducted using the digital M-CHAT-R/F and diagnostic testing with ADOS-Toddler. The study aims to combine information across various autism risk features to develop a risk score based on multiple behaviors, enhancing screening for ASD.

The figure likely represents the odds ratio analysis using the “rhymes and toys” movie as one illustrative example. The figure depicts the variability in the odds ratio estimates for different patterns of expression in children with and without ASD. The figure compares the roc curves for the final movie-level logistic models after leave-one-out cross-validation. The analysis was performed for each video individually, and the model for the “rhymes” movie yielded the strongest predictive ability, followed by the “puppets” and the “bunny” videos. The two “bubbles” movies were the least predictive. The study also explored specific facial movements driving the category of other expressions and how it differs from the neutral expression category, using the CVA algorithm to align facial landmarks and quantify distances between specific facial features.

The study found that children in the ASD group were, on average, 4 months younger than the comparison group, and there was a higher proportion of males in the ASD group. Additionally, there were no differences in the proportion of racial/ethnic minority children between the two groups, and no difference in the proportion of children on Medicaid in the ASD and the non-ASD group.

The new text also discusses the findings related to specific stimuli that elicited high probabilities of other expressions in the participants. The study reported significant differences in the distances of specific facial features between the other versus neutral facial expressions for both the non-ASD and ASD groups. The study demonstrated that children with ASD were more likely to display a neutral expression than children without ASD when watching the series of videos, and the patterns of facial expressions elicited during specific parts of the movies differed between the two groups. The study suggests that engaging brief movies shown on a cost-effective tablet, combined with automated CVA behavioral coding, can be an objective and feasible tool for measuring an early emerging symptom of ASD, namely, increased frequency of neutral facial expressions.

The study also explored the facial landmarks differentiating between the other facial expression category dominant in the non-ASD control group versus the neutral facial expression more common in the ASD group. The analysis identified features such as raised eyebrows and open mouth to play a role in discriminating between the other versus neutral categories. The study acknowledges the limitations of the CVA models of facial expressions, which were trained on adult faces, and the need for further research to build better predictive models from combinations of features.The new text discusses the development of a tablet-based assessment tool using computer vision analysis (CVA) to detect facial movement and affect in young children, particularly focusing on differentiating children with and without ASD based on facial affect. The study involved 104 children aged 16-31 months, including typically developing children, those with non-ASD delays, and those diagnosed with ASD. The participants were recruited from pediatric primary care settings and the community, and screening for ASD was conducted using the digital M-CHAT-R/F and diagnostic testing with ADOS-Toddler. The study aims to combine information across various autism risk features to develop a risk score based on multiple behaviors, enhancing screening for ASD.

The figure likely represents the odds ratio analysis using the “rhymes and toys” movie as one illustrative example. The figure depicts the variability in the odds ratio estimates for different patterns of expression in children with and without ASD. The figure compares the roc curves for the final movie-level logistic models after leave-one-out cross-validation. The analysis was performed for each video individually, and the model for the “rhymes” movie yielded the strongest predictive ability, followed by the “puppets” and the “bunny” videos. The two “bubbles” movies were the least predictive. The study also explored specific facial movements driving the category of other expressions and how it differs from the neutral expression category, using the CVA algorithm to align facial landmarks and quantify distances between specific facial features.

The study found that children in the ASD group were, on average, 4 months younger than the comparison group, and there was a higher proportion of males in the ASD group. Additionally, there were no differences in the proportion of racial/ethnic minority children between the two groups, and no difference in the proportion of children on Medicaid in the ASD and the non-ASD group.

The study also discussed the findings related to specific stimuli that elicited high probabilities of other expressions in the participants. The study reported significant differences in the distances of specific facial features between the other versus neutral facial expressions for both the non-ASD and ASD groups. The study demonstrated that children with ASD were more likely to display a neutral expression than children without ASD when watching the series of videos, and the patterns of facial expressions elicited during specific parts of the movies differed between the two groups. The study suggests that engaging brief movies shown on a cost-effective tablet, combined with automated CVA behavioral coding, can be an objective and feasible tool for measuring an early emerging symptom of ASD, namely, increased frequency of neutral facial expressions.

The study also explored the facial landmarks differentiating between the other facial expression category dominant in the non-ASD control group versus the neutral facial expression more common in the ASD group. The analysis identified features such as raised eyebrows and open mouth to play a role in discriminating between the other versus neutral categories. The study acknowledges the limitations of the CVA models of facial expressions, which were trained on adult faces, and the need for further research to build better predictive models from combinations of features.

The figure 4 in the text shows the analysis of other facial expressions. The panels depict heat maps of aligned landmarks across ASD and non-ASD participants when they were exhibiting neutral and other facial expressions. The color bar indicates the proportion of frames where landmarks were displayed in a given image location. Additionally, the figure includes an example of the landmark distances explored.

The text also discusses the limitations of the study, including the need for future research to train on the engaged/interested facial expression specifically, validate the CVA analysis of emotional facial expressions in larger datasets, and address the small sample size and lack of separate training and testing samples. The study also emphasizes the ongoing research to further differentiate between children with ASD, children with non-ASD developmental delay and/or attention deficit hyperactivity disorder, and typically developing children, and to develop a risk score based on multiple behaviors to assess for risk.The new text discusses the development of a tablet-based assessment tool using computer vision analysis (CVA) to detect facial movement and affect in young children, particularly focusing on differentiating children with and without ASD based on facial affect. The study involved 104 children aged 16-31 months, including typically developing children, those with non-ASD delays, and those diagnosed with ASD. The participants were recruited from pediatric primary care settings and the community, and screening for ASD was conducted using the digital M-CHAT-R/F and diagnostic testing with ADOS-Toddler. The study aims to combine information across various autism risk features to develop a risk score based on multiple behaviors, enhancing screening for ASD.

The figure likely represents the odds ratio analysis using the “rhymes and toys” movie as one illustrative example. The figure depicts the variability in the odds ratio estimates for different patterns of expression in children with and without ASD. The figure compares the roc curves for the final movie-level logistic models after leave-one-out cross-validation. The analysis was performed for each video individually, and the model for the “rhymes” movie yielded the strongest predictive ability, followed by the “puppets” and the “bunny” videos. The two “bubbles” movies were the least predictive. The study also explored specific facial movements driving the category of other expressions and how it differs from the neutral expression category, using the CVA algorithm to align facial landmarks and quantify distances between specific facial features.

The study found that children in the ASD group were, on average, 4 months younger than the comparison group, and there was a higher proportion of males in the ASD group. Additionally, there were no differences in the proportion of racial/ethnic minority children between the two groups, and no difference in the proportion of children on Medicaid in the ASD and the non-ASD group.

The study also discussed the findings related to specific stimuli that elicited high probabilities of other expressions in the participants. The study reported significant differences in the distances of specific facial features between the other versus neutral facial expressions for both the non-ASD and ASD groups. The study demonstrated that children with ASD were more likely to display a neutral expression than children without ASD when watching the series of videos, and the patterns of facial expressions elicited during specific parts of the movies differed between the two groups. The study suggests that engaging brief movies shown on a cost-effective tablet, combined with automated CVA behavioral coding, can be an objective and feasible tool for measuring an early emerging symptom of ASD, namely, increased frequency of neutral facial expressions.

The study also explored the facial landmarks differentiating between the other facial expression category dominant in the non-ASD control group versus the neutral facial expression more common in the ASD group. The analysis identified features such as raised eyebrows and open mouth to play a role in discriminating between the other versus neutral categories. The study acknowledges the limitations of the CVA models of facial expressions, which were trained on adult faces, and the need for further research to build better predictive models from combinations of features.

The references and the detailed technical information about the CVA algorithm have been removed from the new text. The figure described in the new text is an illustrative example of the odds ratio analysis using the “rhymes and toys” movie, showing the variability in the odds ratio estimates for different patterns of expression in children with and without ASD.The new text discusses the development of a tablet-based assessment tool using computer vision analysis (CVA) to detect facial movement and affect in young children, particularly focusing on differentiating children with and without ASD based on facial affect. The study involved 104 children aged 16-31 months, including typically developing children, those with non-ASD delays, and those diagnosed with ASD. The participants were recruited from pediatric primary care settings and the community, and screening for ASD was conducted using the digital M-CHAT-R/F and diagnostic testing with ADOS-Toddler. The study aims to combine information across various autism risk features to develop a risk score based on multiple behaviors, enhancing screening for ASD.

The figure likely represents the odds ratio analysis using the “rhymes and toys” movie as one illustrative example. The figure depicts the variability in the odds ratio estimates for different patterns of expression in children with and without ASD. The figure compares the roc curves for the final movie-level logistic models after leave-one-out cross-validation. The analysis was performed for each video individually, and the model for the “rhymes” movie yielded the strongest predictive ability, followed by the “puppets” and the “bunny” videos. The two “bubbles” movies were the least predictive. The study also explored specific facial movements driving the category of other expressions and how it differs from the neutral expression category, using the CVA algorithm to align facial landmarks and quantify distances between specific facial features.

The study found that children in the ASD group were, on average, 4 months younger than the comparison group, and there was a higher proportion of males in the ASD group. Additionally, there were no differences in the proportion of racial/ethnic minority children between the two groups, and no difference in the proportion of children on Medicaid in the ASD and the non-ASD group.

The study also discussed the findings related to specific stimuli that elicited high probabilities of other expressions in the participants. The study reported significant differences in the distances of specific facial features between the other versus neutral facial expressions for both the non-ASD and ASD groups. The study demonstrated that children with ASD were more likely to display a neutral expression than children without ASD when watching the series of videos, and the patterns of facial expressions elicited during specific parts of the movies differed between the two groups. The study suggests that engaging brief movies shown on a cost-effective tablet, combined with automated CVA behavioral coding, can be an objective and feasible tool for measuring an early emerging symptom of ASD, namely, increased frequency of neutral facial expressions.

The study also explored the facial landmarks differentiating between the other facial expression category dominant in the non-ASD control group versus the neutral facial expression more common in the ASD group. The analysis identified features such as raised eyebrows and open mouth to play a role in discriminating between the other versus neutral categories. The study acknowledges the limitations of the CVA models of facial expressions, which were trained on adult faces, and the need for further research to build better predictive models from combinations of features.

The references and the detailed technical information about the CVA algorithm have been removed from the new text. The figure described in the new text is an illustrative example of the odds ratio analysis using the “rhymes and toys” movie, showing the variability in the odds ratio estimates for different patterns of expression in children with and without ASD.The new text discusses the development of a tablet-based assessment tool using computer vision analysis (CVA) to detect facial movement and affect in young children, particularly focusing on differentiating children with and without ASD based on facial affect. The study involved 104 children aged 16-31 months, including typically developing children, those with non-ASD delays, and those diagnosed with ASD. The participants were recruited from pediatric primary care settings and the community, and screening for ASD was conducted using the digital M-CHAT-R/F and diagnostic testing with ADOS-Toddler. The study aims to combine information across various autism risk features to develop a risk score based on multiple behaviors, enhancing screening for ASD.

The figure likely represents the odds ratio analysis using the “rhymes and toys” movie as one illustrative example. The figure depicts the variability in the odds ratio estimates for different patterns of expression in children with and without ASD. The figure compares the roc curves for the final movie-level logistic models after leave-one-out cross-validation. The analysis was performed for each video individually, and the model for the “rhymes” movie yielded the strongest predictive ability, followed by the “puppets” and the “bunny” videos. The two “bubbles” movies were the least predictive. The study also explored specific facial movements driving the category of other expressions and how it differs from the neutral expression category, using the CVA algorithm to align facial landmarks and quantify distances between specific facial features.

The study found that children in the ASD group were, on average, 4 months younger than the comparison group, and there was a higher proportion of males in the ASD group. Additionally, there were no differences in the proportion of racial/ethnic minority children between the two groups, and no difference in the proportion of children on Medicaid in the ASD and the non-ASD group.

The study also discussed the findings related to specific stimuli that elicited high probabilities of other expressions in the participants. The study reported significant differences in the distances of specific facial features between the other versus neutral facial expressions for both the non-ASD and ASD groups. The study demonstrated that children with ASD were more likely to display a neutral expression than children without ASD when watching the series of videos, and the patterns of facial expressions elicited during specific parts of the movies differed between the two groups. The study suggests that engaging brief movies shown on a cost-effective tablet, combined with automated CVA behavioral coding, can be an objective and feasible tool for measuring an early emerging symptom of ASD, namely, increased frequency of neutral facial expressions.

The study also explored the facial landmarks differentiating between the other facial expression category dominant in the non-ASD control group versus the neutral facial expression more common in the ASD group. The analysis identified features such as raised eyebrows and open mouth to play a role in discriminating between the other versus neutral categories. The study acknowledges the limitations of the CVA models of facial expressions, which were trained on adult faces, and the need for further research to build better predictive models from combinations of features.The new text discusses the development of a tablet-based assessment tool using computer vision analysis (CVA) to detect facial movement and affect in young children, particularly focusing on differentiating children with and without ASD based on facial affect. The study involved 104 children aged 16-31 months, including typically developing children, those with non-ASD delays, and those diagnosed with ASD. The participants were recruited from pediatric primary care settings and the community, and screening for ASD was conducted using the digital M-CHAT-R/F and diagnostic testing with ADOS-Toddler. The study aims to combine information across various autism risk features to develop a risk score based on multiple behaviors, enhancing screening for ASD.

The figure likely represents the odds ratio analysis using the “rhymes and toys” movie as one illustrative example. The figure depicts the variability in the odds ratio estimates for different patterns of expression in children with and without ASD. The figure compares the roc curves for the final movie-level logistic models after leave-one-out cross-validation. The analysis was performed for each video individually, and the model for the “rhymes” movie yielded the strongest predictive ability, followed by the “puppets” and the “bunny” videos. The two “bubbles” movies were the least predictive. The study also explored specific facial movements driving the category of other expressions and how it differs from the neutral expression category, using the CVA algorithm to align facial landmarks and quantify distances between specific facial features.

The study found that children in the ASD group were, on average, 4 months younger than the comparison group, and there was a higher proportion of males in the ASD group. Additionally, there were no differences in the proportion of racial/ethnic minority children between the two groups, and no difference in the proportion of children on Medicaid in the ASD and the non-ASD group.

The study also discussed the findings related to specific stimuli that elicited high probabilities of other expressions in the participants. The study reported significant differences in the distances of specific facial features between the other versus neutral facial expressions for both the non-ASD and ASD groups. The study demonstrated that children with ASD were more likely to display a neutral expression than children without ASD when watching the series of videos, and the patterns of facial expressions elicited during specific parts of the movies differed between the two groups. The study suggests that engaging brief movies shown on a cost-effective tablet, combined with automated CVA behavioral coding, can be an objective and feasible tool for measuring an early emerging symptom of ASD, namely, increased frequency of neutral facial expressions.

The study also explored the facial landmarks differentiating between the other facial expression category dominant in the non-ASD control group versus the neutral facial expression more common in the ASD group. The analysis identified features such as raised eyebrows and open mouth to play a role in discriminating between the other versus neutral categories. The study acknowledges the limitations of the CVA models of facial expressions, which were trained on adult faces, and the need for further research to build better predictive models from combinations of features.

The references and the detailed technical information about the CVA algorithm have been removed from the new text. The figure described in the new text is an illustrative example of the odds ratio analysis using the “rhymes and toys” movie, showing the variability in the odds ratio estimates for different patterns of expression in children with and without ASD.