The research focuses on using robot-assisted tools and child-robot interaction (CRI) to improve the early detection of Autism Spectrum Disorder (ASD) signs in children. The study proposes a system that relies on computer vision and an unstructured and scalable network of RGBD sensors built upon Robot Operating System (ROS) and machine learning algorithms for automated face analysis. The aim is to enhance traditional tools for ASD diagnosis by providing faster and more significant gains from therapeutic intervention compared to classical methods. The use of computer vision and automated video coding is suggested to reduce the delay of ASD diagnosis and provide access to early therapeutic interventions for children with ASD. The research also discusses the limitations of previous systems developed to assist ASD therapists and make diagnoses based on robotic devices, emphasizing the need for autonomous feedback to enhance interaction.

The table data and references have been removed from the text. The figure in the original text has been removed, and it was not described in the text.The research discusses the potential of using robot-assisted tools and child-robot interaction (CRI) to improve the early detection of Autism Spectrum Disorder (ASD) signs in children. It proposes a system that relies on computer vision and an unstructured and scalable network of RGBD sensors built upon Robot Operating System (ROS) and machine learning algorithms for automated face analysis. The aim is to enhance traditional tools for ASD diagnosis by providing faster and more significant gains from therapeutic intervention compared to classical methods. The research also highlights the limitations of previous systems developed to assist ASD therapists and make diagnoses based on robotic devices, emphasizing the need for autonomous feedback to enhance interaction.

The main contributions of the research include the development of a new artificial reasoning module upon a flexible and scalable ROS-based vision system using state-of-the-art machine learning neural models and the proposal and implementation of a supervised child-robot interaction (CRI) based on an open source social robotic platform to enhance the traditional tools for ASD diagnosis using an in-clinic setup protocol. The study also discusses the acceptance and efficiency of technologies used as auxiliary tools for therapy and teaching of individuals with ASD, as well as the potential of social robots for aiding in the diagnosis and therapy of children with ASD.

The research also presents an experimental trial to assess joint-attention behavior employing an in-clinic setup, and discusses previous studies that have used computer vision techniques to measure and analyze child behavior, as well as studies on how children with ASD respond to a robot mediator compared to a human mediator. The work aims to address the limitations of previous studies and develop a closed-loop subsystem for improved interaction.The research discusses the potential of using robot-assisted tools and child-robot interaction (CRI) to improve the early detection of Autism Spectrum Disorder (ASD) signs in children. It proposes a system that relies on computer vision and an unstructured and scalable network of RGBD sensors built upon Robot Operating System (ROS) and machine learning algorithms for automated face analysis. The aim is to enhance traditional tools for ASD diagnosis by providing faster and more significant gains from therapeutic intervention compared to classical methods. The study also highlights the limitations of previous systems developed to assist ASD therapists and make diagnoses based on robotic devices, emphasizing the need for autonomous feedback to enhance interaction.

The main contributions of the research include the development of a new artificial reasoning module upon a flexible and scalable ROS-based vision system using state-of-the-art machine learning neural models and the proposal and implementation of a supervised child-robot interaction (CRI) based on an open source social robotic platform to enhance the traditional tools for ASD diagnosis using an in-clinic setup protocol. The study also discusses the acceptance and efficiency of technologies used as auxiliary tools for therapy and teaching of individuals with ASD, as well as the potential of social robots for aiding in the diagnosis and therapy of children with ASD.

The research also presents an experimental trial to assess joint-attention behavior employing an in-clinic setup, and discusses previous studies that have used computer vision techniques to measure and analyze child behavior, as well as studies on how children with ASD respond to a robot mediator compared to a human mediator. The work aims to address the limitations of previous studies and develop a closed-loop subsystem for improved interaction.

The system architecture overview describes the ROS system used in the research, which is a flexible and scalable open framework for writing modular robot-centered systems. The system consists of a number of nodes for local video processing and robot's behavior estimation, connected at runtime in a peer-to-peer topology. The developed system is composed of two interconnected modules: an artificial reasoning module and a CRI-channel module. The reasoning module implements a distributed architecture for local video processing, while the CRI-channel module has two bidirectional communication channels, a robot-device, and a web-based application to interact with both the child and the therapist.

The figure that was removed from the original text was not described, and the table data and references have been omitted.The research explores the potential of using robot-assisted tools and child-robot interaction (CRI) to enhance the early detection of Autism Spectrum Disorder (ASD) signs in children. It proposes a system based on computer vision and a network of RGBD sensors built on Robot Operating System (ROS) and machine learning algorithms for automated face analysis. The aim is to improve traditional ASD diagnosis tools by enabling faster and more significant gains from therapeutic intervention. The study also addresses the limitations of previous systems developed to assist ASD therapists and make diagnoses based on robotic devices, emphasizing the need for autonomous feedback to enhance interaction.

The main contributions of the research include the development of a new artificial reasoning module and the proposal and implementation of a supervised child-robot interaction (CRI) based on an open source social robotic platform to enhance traditional ASD diagnosis tools using an in-clinic setup protocol. The study also discusses the acceptance and efficiency of technologies used as auxiliary tools for therapy and teaching of individuals with ASD, as well as the potential of social robots for aiding in the diagnosis and therapy of children with ASD.

The research presents an experimental trial to assess joint-attention behavior employing an in-clinic setup and discusses previous studies that have used computer vision techniques to measure and analyze child behavior, as well as studies on how children with ASD respond to a robot mediator compared to a human mediator. The work aims to address the limitations of previous studies and develop a closed-loop subsystem for improved interaction.

Additionally, the research describes the system architecture overview, which includes the ROS system used in the research, consisting of interconnected modules: an artificial reasoning module and a CRI-channel module. The CRI is implemented through the open source platform for social robotics (Opsoro), using a robot called Ono and web-based applications. The Ono robot is designed with a huggable appearance and a neutral identity, allowing the child to participate in defining its identity. It is equipped with motorized arms, facial expressions based on the facial action coding system, and a sound module for positive feedback and reinforcement learning.

The figure that was removed from the original text was not described, and the table data and references have been omitted.The research explores the potential of using robot-assisted tools and child-robot interaction (CRI) to enhance the early detection of Autism Spectrum Disorder (ASD) signs in children. It proposes a system based on computer vision and a network of RGBD sensors built on Robot Operating System (ROS) and machine learning algorithms for automated face analysis. The aim is to improve traditional ASD diagnosis tools by enabling faster and more significant gains from therapeutic intervention. The study also addresses the limitations of previous systems developed to assist ASD therapists and make diagnoses based on robotic devices, emphasizing the need for autonomous feedback to enhance interaction.

The main contributions of the research include the development of a new artificial reasoning module and the proposal and implementation of a supervised child-robot interaction (CRI) based on an open source social robotic platform to enhance traditional ASD diagnosis tools using an in-clinic setup protocol. The study also discusses the acceptance and efficiency of technologies used as auxiliary tools for therapy and teaching of individuals with ASD, as well as the potential of social robots for aiding in the diagnosis and therapy of children with ASD.

The research presents an experimental trial to assess joint-attention behavior employing an in-clinic setup and discusses previous studies that have used computer vision techniques to measure and analyze child behavior, as well as studies on how children with ASD respond to a robot mediator compared to a human mediator. The work aims to address the limitations of previous studies and develop a closed-loop subsystem for improved interaction.

Additionally, the research describes the system architecture overview, which includes the ROS system used in the research, consisting of interconnected modules: an artificial reasoning module and a CRI-channel module. The CRI is implemented through the open source platform for social robotics (Opsoro), using a robot called Ono and web-based applications. The Ono robot is designed with a huggable appearance and a neutral identity, allowing the child to participate in defining its identity. It is equipped with motorized arms, facial expressions based on the facial action coding system, and a sound module for positive feedback and reinforcement learning.

The figure that was removed from the original text was not described, and the table data and references have been omitted. The figure was likely related to the Ono robot, developed through the open source platform for social robotics (Opsoro).

The table data and references have been removed from the text. The table data likely contained information about the adaptability and reproducibility of the Ono robot, including its DIY concept, electronic system, and control and autonomy features. The references were likely related to the cited sources for the machine learning methods for child's face analysis.The research explores the potential of using robot-assisted tools and child-robot interaction (CRI) to enhance the early detection of Autism Spectrum Disorder (ASD) signs in children. It proposes a system based on computer vision and a network of RGBD sensors built on Robot Operating System (ROS) and machine learning algorithms for automated face analysis. The aim is to improve traditional ASD diagnosis tools by enabling faster and more significant gains from therapeutic intervention. The study also addresses the limitations of previous systems developed to assist ASD therapists and make diagnoses based on robotic devices, emphasizing the need for autonomous feedback to enhance interaction.

The main contributions of the research include the development of a new artificial reasoning module and the proposal and implementation of a supervised child-robot interaction (CRI) based on an open source social robotic platform to enhance traditional ASD diagnosis tools using an in-clinic setup protocol. The study also discusses the acceptance and efficiency of technologies used as auxiliary tools for therapy and teaching of individuals with ASD, as well as the potential of social robots for aiding in the diagnosis and therapy of children with ASD.

The research presents an experimental trial to assess joint-attention behavior employing an in-clinic setup and discusses previous studies that have used computer vision techniques to measure and analyze child behavior, as well as studies on how children with ASD respond to a robot mediator compared to a human mediator. The work aims to address the limitations of previous studies and develop a closed-loop subsystem for improved interaction.

Additionally, the research describes the system architecture overview, which includes the ROS system used in the research, consisting of interconnected modules: an artificial reasoning module and a CRI-channel module. The CRI is implemented through the open source platform for social robotics (Opsoro), using a robot called Ono and web-based applications. The Ono robot is designed with a huggable appearance and a neutral identity, allowing the child to participate in defining its identity. It is equipped with motorized arms, facial expressions based on the facial action coding system, and a sound module for positive feedback and reinforcement learning.

The figure that was removed from the original text was not described, and the table data and references have been omitted. The figure was likely related to the Ono robot, developed through the open source platform for social robotics (Opsoro).

The table data and references have been removed from the text. The table data likely contained information about the adaptability and reproducibility of the Ono robot, including its DIY concept, electronic system, and control and autonomy features. The references were likely related to the cited sources for the machine learning methods for child's face analysis.

The figure that was removed from the original text was not described, and the table data and references have been omitted. The figure was likely related to the pipeline algorithm of the automated child's face analysis, which involves processes such as face detection, recognition, landmarks detection, head pose, and eye gaze estimation using deep learning models and specialized local detectors.The research discusses the use of the CLNF technique, which utilizes a linear model called the point distribution model (PDM) to estimate the likelihood of shapes being in a specific class, aiding in model fitting and shape recognition. The PDM is used to describe the shape of a face with landmark points and is learned automatically from labeled data using principal component analysis (PCA). The system also involves transforming the 3D PDM into image space using weak perspective projection and estimating head pose using orthographic camera projection and solving the perspective-n-point (PnP) problem with detected landmarks.

The patch experts scheme is a key component of the CLNF model, capturing spatial characteristics between pixels and learning from multiple illuminations to create landmark detectors and trackers that work in various environments and on different individuals. The learning and inference process is developed using a gradient-based optimization method, and the framework uses patch experts specifically trained to recognize the eyelids, iris, and pupil to estimate eye gaze.

The fitting algorithm of the CLNF-based landmark detection process attempts to find the deformable model parameters that minimize a specific function, with a weight to penalize unlikely shapes and a term representing the misalignment of landmarks in the image. The solution involves maximizing the a posteriori probability of the deformable model parameters, which is solved using an optimization strategy designed specifically for CLNF fitting called non-uniform.

The figure that was removed from the original text was likely related to the pipeline algorithm of the automated child's face analysis, which involves processes such as face detection, recognition, landmarks detection, head pose, and eye gaze estimation using deep learning models and specialized local detectors. The table data and references have been removed from the text. The table data likely contained information about the adaptability and reproducibility of the Ono robot, including its DIY concept, electronic system, and control and autonomy features. The references were likely related to the cited sources for the machine learning methods for child's face analysis.The research explores the potential of using robot-assisted tools and child-robot interaction (CRI) to enhance the early detection of Autism Spectrum Disorder (ASD) signs in children. It proposes a system based on computer vision and a network of RGBD sensors built on Robot Operating System (ROS) and machine learning algorithms for automated face analysis. The aim is to improve traditional ASD diagnosis tools by enabling faster and more significant gains from therapeutic intervention. The study also addresses the limitations of previous systems developed to assist ASD therapists and make diagnoses based on robotic devices, emphasizing the need for autonomous feedback to enhance interaction.

The main contributions of the research include the development of a new artificial reasoning module and the proposal and implementation of a supervised child-robot interaction (CRI) based on an open source social robotic platform to enhance traditional ASD diagnosis tools using an in-clinic setup protocol. The study also discusses the acceptance and efficiency of technologies used as auxiliary tools for therapy and teaching of individuals with ASD, as well as the potential of social robots for aiding in the diagnosis and therapy of children with ASD.

The research presents an experimental trial to assess joint-attention behavior employing an in-clinic setup and discusses previous studies that have used computer vision techniques to measure and analyze child behavior, as well as studies on how children with ASD respond to a robot mediator compared to a human mediator. The work aims to address the limitations of previous studies and develop a closed-loop subsystem for improved interaction.

Additionally, the research describes the system architecture overview, which includes the ROS system used in the research, consisting of interconnected modules: an artificial reasoning module and a CRI-channel module. The CRI is implemented through the open source platform for social robotics (Opsoro), using a robot called Ono and web-based applications. The Ono robot is designed with a huggable appearance and a neutral identity, allowing the child to participate in defining its identity. It is equipped with motorized arms, facial expressions based on the facial action coding system, and a sound module for positive feedback and reinforcement learning.

The figure that was removed from the original text was likely related to the pipeline algorithm of the automated child's face analysis, which involves processes such as face detection, recognition, landmarks detection, head pose, and eye gaze estimation using deep learning models and specialized local detectors. The table data and references have been removed from the text. The table data likely contained information about the adaptability and reproducibility of the Ono robot, including its DIY concept, electronic system, and control and autonomy features. The references were likely related to the cited sources for the machine learning methods for child's face analysis.The research explores the potential of using robot-assisted tools and child-robot interaction (CRI) to enhance the early detection of Autism Spectrum Disorder (ASD) signs in children. It proposes a system based on computer vision and a network of RGBD sensors built on Robot Operating System (ROS) and machine learning algorithms for automated face analysis. The aim is to improve traditional ASD diagnosis tools by enabling faster and more significant gains from therapeutic intervention. The study also addresses the limitations of previous systems developed to assist ASD therapists and make diagnoses based on robotic devices, emphasizing the need for autonomous feedback to enhance interaction.

The main contributions of the research include the development of a new artificial reasoning module and the proposal and implementation of a supervised child-robot interaction (CRI) based on an open source social robotic platform to enhance traditional ASD diagnosis tools using an in-clinic setup protocol. The study also discusses the acceptance and efficiency of technologies used as auxiliary tools for therapy and teaching of individuals with ASD, as well as the potential of social robots for aiding in the diagnosis and therapy of children with ASD.

The research presents an experimental trial to assess joint-attention behavior employing an in-clinic setup and discusses previous studies that have used computer vision techniques to measure and analyze child behavior, as well as studies on how children with ASD respond to a robot mediator compared to a human mediator. The work aims to address the limitations of previous studies and develop a closed-loop subsystem for improved interaction.

Additionally, the research describes the system architecture overview, which includes the ROS system used in the research, consisting of interconnected modules: an artificial reasoning module and a CRI-channel module. The CRI is implemented through the open source platform for social robotics (Opsoro), using a robot called Ono and web-based applications. The Ono robot is designed with a huggable appearance and a neutral identity, allowing the child to participate in defining its identity. It is equipped with motorized arms, facial expressions based on the facial action coding system, and a sound module for positive feedback and reinforcement learning.

The figure that was removed from the original text was likely related to the pipeline algorithm of the automated child's face analysis, which involves processes such as face detection, recognition, landmarks detection, head pose, and eye gaze estimation using deep learning models and specialized local detectors. The table data and references have been removed from the text. The table data likely contained information about the adaptability and reproducibility of the Ono robot, including its DIY concept, electronic system, and control and autonomy features. The references were likely related to the cited sources for the machine learning methods for child's face analysis.

The figure that was removed from the original text was a representation of the interventions room of the in-clinic setup, showing the arrangement of the room with the robot, chairs for the child, caregiver, and therapist, as well as toys attached to the walls. The figure provided a visual understanding of the in-clinic setup for the intervention.

The table data that was removed likely contained information about the adaptability and reproducibility of the Ono robot, including its DIY concept, electronic system, and control and autonomy features. The references were likely related to the cited sources for the machine learning methods for child's face analysis.

The research also discusses the intervention protocol, which involves using a technology-based system as a tool in various stages of the ASD diagnostic process. The framework can be implemented to extract different behavioral features to be assessed, and a specific clinical setup intervention to assess joint attention behaviors is presented. The intervention aims to evaluate the capacity of joint attention, which can be divided into three classes: initiation of joint attention, responding to joint attention bids, and initiation of request behavior. The therapist guides the intervention and leverages the robot device as an alternative channel of communication with the child.

The research also presents the child's nonverbal cues elicited by the CRI, showing the child's responses to look towards the therapist, towards the robot, point, and self-occlusion. This provides insights into the child's interaction with the robot during the intervention.The research explores the potential of using robot-assisted tools and child-robot interaction (CRI) to enhance the early detection of Autism Spectrum Disorder (ASD) signs in children. It proposes a system based on computer vision and a network of RGBD sensors built on Robot Operating System (ROS) and machine learning algorithms for automated face analysis. The aim is to improve traditional ASD diagnosis tools by enabling faster and more significant gains from therapeutic intervention. The study also addresses the limitations of previous systems developed to assist ASD therapists and make diagnoses based on robotic devices, emphasizing the need for autonomous feedback to enhance interaction.

The main contributions of the research include the development of a new artificial reasoning module and the proposal and implementation of a supervised child-robot interaction (CRI) based on an open source social robotic platform to enhance traditional ASD diagnosis tools using an in-clinic setup protocol. The study also discusses the acceptance and efficiency of technologies used as auxiliary tools for therapy and teaching of individuals with ASD, as well as the potential of social robots for aiding in the diagnosis and therapy of children with ASD.

The research presents an experimental trial to assess joint-attention behavior employing an in-clinic setup and discusses previous studies that have used computer vision techniques to measure and analyze child behavior, as well as studies on how children with ASD respond to a robot mediator compared to a human mediator. The work aims to address the limitations of previous studies and develop a closed-loop subsystem for improved interaction.

Additionally, the research describes the system architecture overview, which includes the ROS system used in the research, consisting of interconnected modules: an artificial reasoning module and a CRI-channel module. The CRI is implemented through the open source platform for social robotics (Opsoro), using a robot called Ono and web-based applications. The Ono robot is designed with a huggable appearance and a neutral identity, allowing the child to participate in defining its identity. It is equipped with motorized arms, facial expressions based on the facial action coding system, and a sound module for positive feedback and reinforcement learning.

The figure that was removed from the original text was a representation of the interventions room of the in-clinic setup, showing the arrangement of the room with the robot, chairs for the child, caregiver, and therapist, as well as toys attached to the walls. The figure provided a visual understanding of the in-clinic setup for the intervention.

The table data that was removed likely contained information about the adaptability and reproducibility of the Ono robot, including its DIY concept, electronic system, and control and autonomy features. The references were likely related to the cited sources for the machine learning methods for child's face analysis.

The figure that was removed from the original text was likely related to the pipeline algorithm of the automated child's face analysis, which involves processes such as face detection, recognition, landmarks detection, head pose, and eye gaze estimation using deep learning models and specialized local detectors.

The research also discusses the intervention protocol, which involves using a technology-based system as a tool in various stages of the ASD diagnostic process. The framework can be implemented to extract different behavioral features to be assessed, and a specific clinical setup intervention to assess joint attention behaviors is presented. The intervention aims to evaluate the capacity of joint attention, which can be divided into three classes: initiation of joint attention, responding to joint attention bids, and initiation of request behavior. The therapist guides the intervention and leverages the robot device as an alternative channel of communication with the child.

The research also presents the child's nonverbal cues elicited by the CRI, showing the child's responses to look towards the therapist, towards the robot, point, and self-occlusion. This provides insights into the child's interaction with the robot during the intervention.

The figure that was removed from the original text was a representation of the performance of the child's face analysis pipeline for the case study, showing the execution of tasks such as face detection and recognition, landmarks detection, head pose, and eye gaze estimation. The exercise aimed to direct the child's attention towards objects in the room through stimuli generated by the therapist and the robot.

The subjects involved in the experiments included three children without confirmed ASD diagnosis but with risk factors, and three typically developing (TD) children as the control group. The goal was to analyze the baseline of the child's behavior and establish differences in the behavioral reaction between TD and ASD children for stimuli generated through CRI and leverage the novelty effect raised by the robot mediator.

The research also reports the performance of video processing in the proof of concept session, including the child's face detection and recognition, and the evolution over time of the child's head/neck rotation for the TD group.

Overall, the research presents a comprehensive exploration of using robot-assisted tools and child-robot interaction to improve the early detection of ASD signs in children, with a focus on the development and implementation of a system based on computer vision and social robotics to enhance traditional ASD diagnosisThe research explores the potential of using robot-assisted tools and child-robot interaction (CRI) to enhance the early detection of Autism Spectrum Disorder (ASD) signs in children. It proposes a system based on computer vision and a network of RGBD sensors built on Robot Operating System (ROS) and machine learning algorithms for automated face analysis. The aim is to improve traditional ASD diagnosis tools by enabling faster and more significant gains from therapeutic intervention. The study also addresses the limitations of previous systems developed to assist ASD therapists and make diagnoses based on robotic devices, emphasizing the need for autonomous feedback to enhance interaction.

The main contributions of the research include the development of a new artificial reasoning module and the proposal and implementation of a supervised child-robot interaction (CRI) based on an open source social robotic platform to enhance traditional ASD diagnosis tools using an in-clinic setup protocol. The study also discusses the acceptance and efficiency of technologies used as auxiliary tools for therapy and teaching of individuals with ASD, as well as the potential of social robots for aiding in the diagnosis and therapy of children with ASD.

The research presents an experimental trial to assess joint-attention behavior employing an in-clinic setup and discusses previous studies that have used computer vision techniques to measure and analyze child behavior, as well as studies on how children with ASD respond to a robot mediator compared to a human mediator. The work aims to address the limitations of previous studies and develop a closed-loop subsystem for improved interaction.

Additionally, the research describes the system architecture overview, which includes the ROS system used in the research, consisting of interconnected modules: an artificial reasoning module and a CRI-channel module. The CRI is implemented through the open source platform for social robotics (Opsoro), using a robot called Ono and web-based applications. The Ono robot is designed with a huggable appearance and a neutral identity, allowing the child to participate in defining its identity. It is equipped with motorized arms, facial expressions based on the facial action coding system, and a sound module for positive feedback and reinforcement learning.

The figure that was removed from the original text was a representation of the interventions room of the in-clinic setup, showing the arrangement of the room with the robot, chairs for the child, caregiver, and therapist, as well as toys attached to the walls. The figure provided a visual understanding of the in-clinic setup for the intervention.

The research also discusses the intervention protocol, which involves using a technology-based system as a tool in various stages of the ASD diagnostic process. The framework can be implemented to extract different behavioral features to be assessed, and a specific clinical setup intervention to assess joint attention behaviors is presented. The intervention aims to evaluate the capacity of joint attention, which can be divided into three classes: initiation of joint attention, responding to joint attention bids, and initiation of request behavior. The therapist guides the intervention and leverages the robot device as an alternative channel of communication with the child.

The research also presents the child's nonverbal cues elicited by the CRI, showing the child's responses to look towards the therapist, towards the robot, point, and self-occlusion. This provides insights into the child's interaction with the robot during the intervention.

The figure that was removed from the original text was a representation of the performance of the child's face analysis pipeline for the case study, showing the execution of tasks such as face detection and recognition, landmarks detection, head pose, and eye gaze estimation. The exercise aimed to direct the child's attention towards objects in the room through stimuli generated by the therapist and the robot.

The subjects involved in the experiments included three children without confirmed ASD diagnosis but with risk factors, and three typically developing (TD) children as the control group. The goal was to analyze the baseline of the child's behavior and establish differences in the behavioral reaction between TD and ASD children for stimuli generated through CRI and leverage the novelty effect raised by the robot mediator.

The research also reports the performance of video processing in the proof of concept session, including the child's face detection and recognition, and the evolution over time of the child's head/neck rotation for the TD group.

Overall, the research presents a comprehensive exploration of using robot-assisted tools and child-robot interaction to improve the early detection of ASD signs in children, with a focus on the development and implementation of a system based on computer vision and social robotics to enhance traditional ASD diagnosis.The figure that was removed from the original text was likely related to the evolution over time of the child's head/neck rotation (yaw rotation) for an ASD group. The figure showed the child's responses to the robot mediator and therapist, including behaviors of joint attention and comfort. The study involved three children without confirmed ASD diagnosis but with risk factors, and three typically developing (TD) children as the control group. The research aimed to analyze differences in behavioral reactions between the two groups for stimuli generated through child-robot interaction (CRI) and leverage the novelty effect raised by the robot mediator.

The analysis revealed that children in the ASD group maintained more visual contact with the robot compared to the therapist and exhibited more interest in the robot platform compared to the TD children. However, the performance of the children in the activities of joint attention did not significantly improve when prompted by the robot. The children with ASD also exhibited less discomfort regarding the session, and in some cases, showed appearance of verbal and non-verbal pro-social behaviors. On the other hand, the TD children showed the ability to divide attention between the robot and the therapist from the beginning to the end of the intervention, exhibiting comfort in every moment.

The novelty of a robot mediator at the diagnostic session was analyzed as an additional stimulus of the CRI. The children of the ASD group showed more behavior modification (attention and comfort) produced by the robot interaction at the beginning of the CRI, remaining until the end of the session. In contrast, the children of the TD group responded to the novelty effect of the robot mediator from the time they entered the room and saw the robot until the beginning of the therapist presentation.

Overall, the research provides a comprehensive exploration of using robot-assisted tools and child-robot interaction to improve the early detection of ASD signs in children, with a focus on the development and implementation of a system based on computer vision and social robotics to enhance traditional ASD diagnosis.The research explores the potential of using robot-assisted tools and child-robot interaction (CRI) to enhance the early detection of Autism Spectrum Disorder (ASD) signs in children. It proposes a system based on computer vision and a network of RGBD sensors built on Robot Operating System (ROS) and machine learning algorithms for automated face analysis. The aim is to improve traditional ASD diagnosis tools by enabling faster and more significant gains from therapeutic intervention. The study also addresses the limitations of previous systems developed to assist ASD therapists and make diagnoses based on robotic devices, emphasizing the need for autonomous feedback to enhance interaction.

The main contributions of the research include the development of a new artificial reasoning module and the proposal and implementation of a supervised child-robot interaction (CRI) based on an open source social robotic platform to enhance traditional ASD diagnosis tools using an in-clinic setup protocol. The study also discusses the acceptance and efficiency of technologies used as auxiliary tools for therapy and teaching of individuals with ASD, as well as the potential of social robots for aiding in the diagnosis and therapy of children with ASD.

The research presents an experimental trial to assess joint-attention behavior employing an in-clinic setup and discusses previous studies that have used computer vision techniques to measure and analyze child behavior, as well as studies on how children with ASD respond to a robot mediator compared to a human mediator. The work aims to address the limitations of previous studies and develop a closed-loop subsystem for improved interaction.

Additionally, the research describes the system architecture overview, which includes the ROS system used in the research, consisting of interconnected modules: an artificial reasoning module and a CRI-channel module. The CRI is implemented through the open source platform for social robotics (Opsoro), using a robot called Ono and web-based applications. The Ono robot is designed with a huggable appearance and a neutral identity, allowing the child to participate in defining its identity. It is equipped with motorized arms, facial expressions based on the facial action coding system, and a sound module for positive feedback and reinforcement learning.

The figure that was removed from the original text was likely related to the pipeline algorithm of the automated child's face analysis, which involves processes such as face detection, recognition, landmarks detection, head pose, and eye gaze estimation using deep learning models and specialized local detectors. The table data and references have been removed from the text. The table data likely contained information about the adaptability and reproducibility of the Ono robot, including its DIY concept, electronic system, and control and autonomy features. The references were likely related to the cited sources for the machine learning methods for child's face analysis.The research explores the potential of using robot-assisted tools and child-robot interaction (CRI) to enhance the early detection of Autism Spectrum Disorder (ASD) signs in children. It proposes a system based on computer vision and a network of RGBD sensors built on Robot Operating System (ROS) and machine learning algorithms for automated face analysis. The aim is to improve traditional ASD diagnosis tools by enabling faster and more significant gains from therapeutic intervention. The study also addresses the limitations of previous systems developed to assist ASD therapists and make diagnoses based on robotic devices, emphasizing the need for autonomous feedback to enhance interaction.

The main contributions of the research include the development of a new artificial reasoning module and the proposal and implementation of a supervised child-robot interaction (CRI) based on an open source social robotic platform to enhance traditional ASD diagnosis tools using an in-clinic setup protocol. The study also discusses the acceptance and efficiency of technologies used as auxiliary tools for therapy and teaching of individuals with ASD, as well as the potential of social robots for aiding in the diagnosis and therapy of children with ASD.

The research presents an experimental trial to assess joint-attention behavior employing an in-clinic setup and discusses previous studies that have used computer vision techniques to measure and analyze child behavior, as well as studies on how children with ASD respond to a robot mediator compared to a human mediator. The work aims to address the limitations of previous studies and develop a closed-loop subsystem for improved interaction.

Additionally, the research describes the system architecture overview, which includes the ROS system used in the research, consisting of interconnected modules: an artificial reasoning module and a CRI-channel module. The CRI is implemented through the open source platform for social robotics (Opsoro), using a robot called Ono and web-based applications. The Ono robot is designed with a huggable appearance and a neutral identity, allowing the child to participate in defining its identity. It is equipped with motorized arms, facial expressions based on the facial action coding system, and a sound module for positive feedback and reinforcement learning.

The research also discusses the intervention protocol, which involves using a technology-based system as a tool in various stages of the ASD diagnostic process. The framework can be implemented to extract different behavioral features to be assessed, and a specific clinical setup intervention to assess joint attention behaviors is presented. The intervention aims to evaluate the capacity of joint attention, which can be divided into three classes: initiation of joint attention, responding to joint attention bids, and initiation of request behavior. The therapist guides the intervention and leverages the robot device as an alternative channel of communication with the child.

The research also presents the child's nonverbal cues elicited by the CRI, showing the child's responses to look towards the therapist, towards the robot, point, and self-occlusion. This provides insights into the child's interaction with the robot during the intervention.

The figure that was removed from the original text was a representation of the performance of the child's face analysis pipeline for the case study, showing the execution of tasks such as face detection and recognition, landmarks detection, head pose, and eye gaze estimation. The exercise aimed to direct the child's attention towards objects in the room through stimuli generated by the therapist and the robot.

The subjects involved in the experiments included three children without confirmed ASD diagnosis but with risk factors, and three typically developing (TD) children as the control group. The goal was to analyze the baseline of the child's behavior and establish differences in the behavioral reaction between TD and ASD children for stimuli generated through CRI and leverage the novelty effect raised by the robot mediator.

Overall, the research presents a comprehensive exploration of using robot-assisted tools and child-robot interaction to improve the early detection of ASD signs in children, with a focus on the development and implementation of a system based on computer vision and social robotics to enhance traditional ASD diagnosis.The research explores the potential of using robot-assisted tools and child-robot interaction (CRI) to enhance the early detection of Autism Spectrum Disorder (ASD) signs in children. It proposes a system based on computer vision and a network of RGBD sensors built on Robot Operating System (ROS) and machine learning algorithms for automated face analysis. The aim is to improve traditional ASD diagnosis tools by enabling faster and more significant gains from therapeutic intervention. The study also addresses the limitations of previous systems developed to assist ASD therapists and make diagnoses based on robotic devices, emphasizing the need for autonomous feedback to enhance interaction.

The main contributions of the research include the development of a new artificial reasoning module and the proposal and implementation of a supervised child-robot interaction (CRI) based on an open source social robotic platform to enhance traditional ASD diagnosis tools using an in-clinic setup protocol. The study also discusses the acceptance and efficiency of technologies used as auxiliary tools for therapy and teaching of individuals with ASD, as well as the potential of social robots for aiding in the diagnosis and therapy of children with ASD.

The research presents an experimental trial to assess joint-attention behavior employing an in-clinic setup and discusses previous studies that have used computer vision techniques to measure and analyze child behavior, as well as studies on how children with ASD respond to a robot mediator compared to a human mediator. The work aims to address the limitations of previous studies and develop a closed-loop subsystem for improved interaction.

Additionally, the research describes the system architecture overview, which includes the ROS system used in the research, consisting of interconnected modules: an artificial reasoning module and a CRI-channel module. The CRI is implemented through the open source platform for social robotics (Opsoro), using a robot called Ono and web-based applications. The Ono robot is designed with a huggable appearance and a neutral identity, allowing the child to participate in defining its identity. It is equipped with motorized arms, facial expressions based on the facial action coding system, and a sound module for positive feedback and reinforcement learning.

The research also discusses the intervention protocol, which involves using a technology-based system as a tool in various stages of the ASD diagnostic process. The framework can be implemented to extract different behavioral features to be assessed, and a specific clinical setup intervention to assess joint attention behaviors is presented. The intervention aims to evaluate the capacity of joint attention, which can be divided into three classes: initiation of joint attention, responding to joint attention bids, and initiation of request behavior. The therapist guides the intervention and leverages the robot device as an alternative channel of communication with the child.

The research also presents the child's nonverbal cues elicited by the CRI, showing the child's responses to look towards the therapist, towards the robot, point, and self-occlusion. This provides insights into the child's interaction with the robot during the intervention.

The study involved three children without confirmed ASD diagnosis but with risk factors, and three typically developing (TD) children as the control group. The goal was to analyze the baseline of the child's behavior and establish differences in the behavioral reaction between TD and ASD children for stimuli generated through CRI and leverage the novelty effect raised by the robot mediator.

Overall, the research presents a comprehensive exploration of using robot-assisted tools and child-robot interaction to improve the early detection of ASD signs in children, with a focus on the development and implementation of a system based on computer vision and social robotics to enhance traditional ASD diagnosis.The research explores the potential of using robot-assisted tools and child-robot interaction (CRI) to enhance the early detection of Autism Spectrum Disorder (ASD) signs in children. It proposes a system based on computer vision and a network of RGBD sensors built on Robot Operating System (ROS) and machine learning algorithms for automated face analysis. The aim is to improve traditional ASD diagnosis tools by enabling faster and more significant gains from therapeutic intervention. The study also addresses the limitations of previous systems developed to assist ASD therapists and make diagnoses based on robotic devices, emphasizing the need for autonomous feedback to enhance interaction.

The main contributions of the research include the development of a new artificial reasoning module and the proposal and implementation of a supervised child-robot interaction (CRI) based on an open source social robotic platform to enhance traditional ASD diagnosis tools using an in-clinic setup protocol. The study also discusses the acceptance and efficiency of technologies used as auxiliary tools for therapy and teaching of individuals with ASD, as well as the potential of social robots for aiding in the diagnosis and therapy of children with ASD.

The research presents an experimental trial to assess joint-attention behavior employing an in-clinic setup and discusses previous studies that have used computer vision techniques to measure and analyze child behavior, as well as studies on how children with ASD respond to a robot mediator compared to a human mediator. The work aims to address the limitations of previous studies and develop a closed-loop subsystem for improved interaction.

Additionally, the research describes the system architecture overview, which includes the ROS system used in the research, consisting of interconnected modules: an artificial reasoning module and a CRI-channel module. The CRI is implemented through the open source platform for social robotics (Opsoro), using a robot called Ono and web-based applications. The Ono robot is designed with a huggable appearance and a neutral identity, allowing the child to participate in defining its identity. It is equipped with motorized arms, facial expressions based on the facial action coding system, and a sound module for positive feedback and reinforcement learning.